{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a708f80d-ba3e-4a4b-a1bc-0fe0dcf41f74",
   "metadata": {},
   "source": [
    "# Нумерация каждого сустава"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2eb63-2df8-4aa5-b92b-79075a25d47c",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height: 300px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be5bd7-337a-452d-9a71-d17873cc1472",
   "metadata": {},
   "source": [
    "# Код для определения человека в определенном месте в кадре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c795210c-94cc-45c8-8f74-c7795de2418c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FasterRCNN_ResNet50_FPN_Weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Шаг 1: Загрузка модели\u001b[39;00m\n\u001b[0;32m      8\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mFasterRCNN_ResNet50_FPN_Weights\u001b[49m\u001b[38;5;241m.\u001b[39mDEFAULT\n\u001b[0;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Загрузка видеопотока\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FasterRCNN_ResNet50_FPN_Weights' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "\n",
    "# Загрузка модели\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "# Загрузка видеопотока\n",
    "cap = cv2.VideoCapture(0)  # 0 означает использование первой камеры\n",
    "\n",
    "# Определение класса \"человек\"\n",
    "PERSON_CLASS_ID = 1\n",
    "\n",
    "# Преобразования для входного изображения\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Координаты интересующей области (x1, y1, x2, y2)\n",
    "area_x1, area_y1, area_x2, area_y2 = 0, 0, 100, 200\n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "\n",
    "    # Обрезка кадра до заданной области\n",
    "    roi = img[area_y1:area_y2, area_x1:area_x2]\n",
    "\n",
    "    # Преобразование кадра\n",
    "    image = transform(roi)\n",
    "    image = image.unsqueeze(0)  # Добавляем batch dimension\n",
    "\n",
    "    # Применение модели для обнаружения объектов\n",
    "    with torch.no_grad():\n",
    "        predictions = model(image)\n",
    "    \n",
    "    # Анализ результатов\n",
    "    labels = predictions[0]['labels'].numpy()\n",
    "    boxes = predictions[0]['boxes'].detach().numpy()\n",
    "    scores = predictions[0]['scores'].detach().numpy()\n",
    "\n",
    "    # Проверка наличия человека\n",
    "    for label, box, score in zip(labels, boxes, scores):\n",
    "        if label == PERSON_CLASS_ID and score > 0.5:\n",
    "            x1, y1, x2, y2 = box.astype(int)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(img, f'Person: {score:.2f}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    # Отображение кадра\n",
    "    cv2.imshow('Frame', img)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Освобождение ресурсов\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb23e36e-5b5c-416d-ba90-1a08ff4b3795",
   "metadata": {},
   "source": [
    "# Импортируемые библиотеки и инициализация базы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4354fe5-66e3-4b7b-879a-10617d0b551d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x21caaca6e70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db\n",
    "from firebase_admin import storage\n",
    "from datetime import datetime\n",
    "\n",
    "cred = credentials.Certificate(\"serviceAccountKey.json\")\n",
    "firebase_admin.initialize_app(cred, {'databaseURL': \"https://facedetectiondb-6bd7e-default-rtdb.firebaseio.com/\",\n",
    "                                     'storageBucket': 'facedetectiondb-6bd7e.appspot.com'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c257788a-39f2-439f-9448-b635cb570366",
   "metadata": {},
   "source": [
    "# Функция по нахождению угла между тремя точками на теле"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bd8bc99-5a81-4c12-a861-0f76a50bbf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "\n",
    "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
    "    angle = np.abs(radians * 180.0/np.pi)\n",
    "\n",
    "    if angle > 180.0:\n",
    "        angle = 360 - angle\n",
    "\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b179ed5-0a7b-4676-a08b-07884a658602",
   "metadata": {},
   "source": [
    "# Основная часть кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1b69f-3078-4cbf-b67e-e0d708aec66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация моделей для определения костей\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Переменные для подсчета присядов\n",
    "stage = \"up\"\n",
    "sit_counter = 0\n",
    "\n",
    "# Инициализация сущностей базы данных\n",
    "ref = db.reference('Employees')\n",
    "\n",
    "# Добавление лиц в базу данных\n",
    "data = {\n",
    "    \"963852\":\n",
    "        {\n",
    "            'name': 'Elon Musk',\n",
    "            'amount_of_walk_aways': 0,\n",
    "            'last_time_attendance': '2024-07-11 00:07:23',\n",
    "            'counter': 0\n",
    "        },\n",
    "    \"185249\":\n",
    "        {\n",
    "            'name': 'Eliot Alderson',\n",
    "            'amount_of_walk_aways': 0,\n",
    "            'last_time_attendance': '2024-07-11 00:07:23',\n",
    "            'counter': 0\n",
    "        },\n",
    "}\n",
    "\n",
    "for key, value in data.items():\n",
    "    ref.child(key).set(value)\n",
    "\n",
    "# Импорт лиц для базы данных\n",
    "\n",
    "folderPath = 'Images'\n",
    "PathList = os.listdir(folderPath)\n",
    "imgList = []\n",
    "employeeID = []\n",
    "for path in PathList:\n",
    "    imgList.append(cv2.imread(os.path.join(folderPath, path)))\n",
    "    employeeID.append(os.path.splitext(path)[0])\n",
    "\n",
    "    fileName = f'{folderPath}/{path}'\n",
    "    bucket = storage.bucket()\n",
    "    blob = bucket.blob(fileName)\n",
    "    blob.upload_from_filename(fileName)\n",
    "\n",
    "\n",
    "def findEncodings(imagesList):\n",
    "    encodeList = []\n",
    "    for img in imagesList:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encode = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encode)\n",
    "\n",
    "    return encodeList\n",
    "\n",
    "print('Encoding Started')\n",
    "encodeListKnown = findEncodings(imgList)\n",
    "encodeListKnownIds = [encodeListKnown, employeeID]\n",
    "print('Encoding Complete')\n",
    "\n",
    "file = open(\"EncodeFile.p\", 'wb')\n",
    "pickle.dump(encodeListKnownIds, file)\n",
    "file.close()\n",
    "print('File Saved')\n",
    "\n",
    "bucket = storage.bucket()\n",
    "\n",
    "# Инициализация видео потока\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "imgBackground = cv2.imread('Resources/background.png')\n",
    "\n",
    "folderModePath = 'Resources/Modes'\n",
    "modePathList = os.listdir(folderModePath)\n",
    "imgModeList = []\n",
    "for path in modePathList:\n",
    "    imgModeList.append(cv2.imread(os.path.join(folderModePath, path)))\n",
    "\n",
    "# Загрузка файла кодировки\n",
    "print('Loading encode file')\n",
    "file = open('EncodeFile.p', 'rb')\n",
    "encodeListKnownIds = pickle.load(file)\n",
    "file.close()\n",
    "encodeListKnown, employeeID = encodeListKnownIds\n",
    "\n",
    "print('Encode file loaded')\n",
    "\n",
    "\n",
    "modeType = 0\n",
    "counter = 0\n",
    "id = -1\n",
    "imageEmployee = []\n",
    "\n",
    "# Основной цикл\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while True:\n",
    "        # Переменные для захвата видео\n",
    "        success, img = cap.read()\n",
    "\n",
    "        # Конвертирование видеоряда\n",
    "        imgS = cv2.resize(img, (0, 0), None, 0.25, 0.25)\n",
    "        imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        faceCurFrame = face_recognition.face_locations(imgS)\n",
    "        encodeCurFrame = face_recognition.face_encodings(imgS, faceCurFrame)\n",
    "    \n",
    "        imgBackground[162:162 + 480, 55:55 + 640] = img\n",
    "        imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    \n",
    "        for encodeFace, faceLoc in zip(encodeCurFrame, faceCurFrame):\n",
    "            matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
    "            faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
    "    \n",
    "            matchIndex = np.argmin(faceDis)\n",
    "            if matches[matchIndex]:\n",
    "                print(employeeID[matchIndex])\n",
    "                id = employeeID[matchIndex]\n",
    "                if counter == 0:\n",
    "                    counter = 1\n",
    "                    modeType = 1\n",
    "\n",
    "        # Блок для опеределения костей и нахождения угла между ними\n",
    "        imgBackground = cv2.cvtColor(imgBackground, cv2.COLOR_BGR2RGB)\n",
    "        imgBackground.flags.writeable = False\n",
    "        results = pose.process(imgBackground)\n",
    "        imgBackground.flags.writeable = True\n",
    "        imgBackground = cv2.cvtColor(imgBackground, cv2.COLOR_RGB2BGR)\n",
    "        employeeInfo = db.reference(f'Employees/{id}').get()\n",
    "        try:         \n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Получение координат\n",
    "            left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            \n",
    "            right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            \n",
    "            left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "            left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "            left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "            \n",
    "            right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "            right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "            right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x, landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "            \n",
    "            # Вычисление углов\n",
    "            angle_left_hip = calculate_angle(left_shoulder, left_hip, left_knee)\n",
    "            angle_right_hip = calculate_angle(right_shoulder, right_hip, right_knee)\n",
    "            angle_left_knee = calculate_angle(left_ankle, left_knee, left_hip)\n",
    "            angle_right_knee = calculate_angle(right_ankle, right_knee, right_hip)\n",
    "            print(angle_left_hip)\n",
    "            print(angle_right_hip)\n",
    "            print(angle_left_knee)\n",
    "            print(angle_right_knee)\n",
    "\n",
    "            cv2.putText(imgBackground, str(int(angle_left_hip)), tuple(np.multiply(left_hip, [640, 480]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(imgBackground, str(int(angle_right_hip)), tuple(np.multiply(right_hip, [640, 480]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(imgBackground, str(int(angle_left_knee)), tuple(np.multiply(left_knee, [640, 480]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "            cv2.putText(imgBackground, str(int(angle_right_knee)), tuple(np.multiply(right_knee, [640, 480]).astype(int)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Логика подсчета присядов\n",
    "            if (angle_left_hip < 110 or angle_right_hip < 110 or angle_left_knee < 110 or angle_right_knee < 110) and stage == \"up\":\n",
    "                stage = \"down\"\n",
    "                ref = db.reference(f'Employees/{id}')\n",
    "                employeeInfo['amount_of_walk_aways'] += 1\n",
    "                ref.child('amount_of_walk_aways').set(employeeInfo['amount_of_walk_aways'])\n",
    "                sit_counter += 1\n",
    "            if angle_left_hip > 160 and angle_right_hip > 160 and angle_left_knee > 160 and angle_right_knee > 160 and stage ==\"down\":\n",
    "                stage = \"up\"              \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cv2.rectangle(imgBackground, (0,0), (215, 72), (50, 205, 50), -1)\n",
    "\n",
    "        cv2.putText(imgBackground, 'SITS COUNT', (15,15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(imgBackground, str(sit_counter), (10,55), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(imgBackground, 'STAGE', (90,15), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,0), 1, cv2.LINE_AA)\n",
    "        cv2.putText(imgBackground, stage, (90,55), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Вывод вычислений\n",
    "        mp_drawing.draw_landmarks(imgBackground, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    \n",
    "        if counter != 0:\n",
    "    \n",
    "            if counter == 1:\n",
    "                # Получение данных\n",
    "                employeeInfo = db.reference(f'Employees/{id}').get()\n",
    "                print(employeeInfo)\n",
    "                # Получение изображения\n",
    "                blob = bucket.get_blob(f'Images/{id}.png')\n",
    "                array = np.frombuffer(blob.download_as_string(), dtype=np.uint8)\n",
    "                imageEmployee = cv2.imdecode(array, cv2.COLOR_BGRA2BGR)\n",
    "                # Обновление базы данных\n",
    "                datetimeObject = datetime.strptime(employeeInfo['last_time_attendance'], \"%Y-%m-%d %H:%M:%S\")\n",
    "                timeElapsed = (datetime.now() - datetimeObject).total_seconds()\n",
    "                print(timeElapsed)\n",
    "    \n",
    "                ref = db.reference(f'Employees/{id}')\n",
    "                employeeInfo['amount_of_walk_aways'] += 1\n",
    "                ref.child('amount_of_walk_aways').set(employeeInfo['amount_of_walk_aways'])\n",
    "                ref.child('last_time_attendance').set(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "                cv2.putText(imgBackground, str(employeeInfo['amount_of_walk_aways']), (400,300), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 2)\n",
    "\n",
    "            # Изменения HUD элементов\n",
    "            if 10 < counter <= 20:\n",
    "                modeType = 2\n",
    "    \n",
    "            imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "    \n",
    "            if counter <= 10:\n",
    "    \n",
    "                cv2.putText(imgBackground, str(employeeInfo['amount_of_walk_aways']), (861, 125),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
    "                cv2.putText(imgBackground, str(id), (1006, 493),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "                (w, h), _ = cv2.getTextSize(employeeInfo['name'], cv2.FONT_HERSHEY_SIMPLEX, 1, 1)\n",
    "                offset = (414 - w) // 2\n",
    "                cv2.putText(imgBackground, str(employeeInfo['name']), (808 + offset, 445),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 1)\n",
    "    \n",
    "                imgBackground[175:175 + 216, 909:909 + 216] = imageEmployee\n",
    "    \n",
    "            counter += 1\n",
    "    \n",
    "            if counter >= 20:\n",
    "                counter = 0\n",
    "                modeType = 0\n",
    "                employeeInfo = []\n",
    "                imageEmployee = []\n",
    "                imgBackground[44:44 + 633, 808:808 + 414] = imgModeList[modeType]\n",
    "\n",
    "        # Отображение кадра\n",
    "        cv2.imshow('Face Attendance', imgBackground)\n",
    "        cv2.waitKey(1)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Освобождение ресурсов\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ecb03-81c2-49d2-8635-29a89b5724ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
